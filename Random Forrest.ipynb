{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset And Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_data = pd.concat([df_train, df_test], ignore_index=True)  # Concatenate train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sex\n",
    "df_data['Sex_Code'] = df_data['Sex'].map({'female' : 1, 'male' : 0}).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing fare values\n",
    "df_data['Fare'] = df_data['Fare'].fillna(df_data['Fare'].median())\n",
    "\n",
    "# Making Bins\n",
    "df_data['FareBin_5'] = pd.qcut(df_data['Fare'], 5)\n",
    "\n",
    "label = LabelEncoder()\n",
    "df_data['FareBin_Code_5'] = label.fit_transform(df_data['FareBin_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Another way of binning, by clustering, incoporating the deck information\n",
    "\"\"\"\n",
    "def get_deck(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return cabin[0]\n",
    "\n",
    "def deck_mapping(deck):\n",
    "    deck_mapping_dict = {'Unknown': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 8}\n",
    "    return deck_mapping_dict.get(deck, 0)\n",
    "\n",
    "df_data['Deck'] = df_data['Cabin'].apply(get_deck)\n",
    "df_data['Deck_encode'] = df_data['Deck'].apply(deck_mapping)\n",
    "\n",
    "df_data['Fare'] = df_data['Fare'].fillna(df_data['Fare'].median())\n",
    "fare_weight = 0.05\n",
    "df_data['Fare_Scaled'] = df_data['Fare'] * fare_weight\n",
    "\n",
    "features_for_clustering = df_data[['Fare_Scaled', 'Deck_encode']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "df_data['FareDeck_5'] = kmeans.fit_predict(features_for_clustering)\n",
    "\n",
    "label = LabelEncoder()\n",
    "df_data['FareDeck_Code_5'] = label.fit_transform(df_data['FareDeck_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the clustering\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Fare', y='Deck_encode', hue='FareDeck_5', palette='viridis', data=df_data, s=100, alpha=0.6, edgecolor='w')\n",
    "plt.title('Fare and Cabin Clustering')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Deck (Encoded)')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family_size\n",
    "df_data['Family_size'] = df_data['SibSp'] + df_data['Parch'] + 1\n",
    "\n",
    "# how about the fare values of deplicate tickets \n",
    "deplicate_ticket = []\n",
    "for tk in df_data.Ticket.unique():\n",
    "    tem = df_data.loc[df_data.Ticket == tk, 'Fare']\n",
    "    if tem.count() > 1:\n",
    "        deplicate_ticket.append(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare','Cabin','Family_size','Survived']])\n",
    "deplicate_ticket = pd.concat(deplicate_ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature found out in [Blood is thicker than water & friendship forever](https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever/code) by S.Xu. \n",
    "df_data['Connected_Survival'] = 0.5 # default \n",
    "for _, df_grp in df_data.groupby('Ticket'):\n",
    "    if (len(df_grp) > 1):\n",
    "        for ind, row in df_grp.iterrows():\n",
    "            smax = df_grp.drop(ind)['Survived'].max()\n",
    "            smin = df_grp.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one way of filling in missing age values\n",
    "\"\"\"\n",
    "# extracted title using name\n",
    "df_data['Title'] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df_data['Title'] = df_data['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n",
    "                                               'Dr', 'Dona', 'Jonkheer', \n",
    "                                                'Major','Rev','Sir'],'Rare') \n",
    "df_data['Title'] = df_data['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\n",
    "df_data['Title'] = df_data['Title'].replace(['Lady'],'Mrs')\n",
    "df_data['Title'] = df_data['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })\n",
    "Ti_pred = df_data.groupby('Title')['Age'].median().values\n",
    "df_data['Ti_Age'] = df_data['Age']\n",
    "# Filling the missing age\n",
    "for i in range(0,5):\n",
    "    df_data.loc[(df_data.Age.isnull()) & (df_data.Title == i),'Ti_Age'] = Ti_pred[i]\n",
    "df_data['Ti_Age'] = df_data['Ti_Age'].astype('int')\n",
    "\n",
    "# extract minor\n",
    "df_data['Age_copy'] = df_data['Age'].fillna(-1)\n",
    "df_data['Minor'] = (df_data['Age_copy'] < 14.0) & (df_data['Age_copy']>= 0)\n",
    "df_data['Minor'] = df_data['Minor'] * 1\n",
    "# We could capture more 8 Master in Pclass = 3 by filling missing age \n",
    "df_data['Ti_Minor'] = ((df_data['Ti_Age']) < 14.0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one way of filling in missing age values, by imputing\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest_impute(df):\n",
    "    known_age = df[df['New_Age'].notnull()]\n",
    "    unknown_age = df[df['New_Age'].isnull()]\n",
    "    \n",
    "    X_train = known_age[['Pclass', 'Title']]\n",
    "    y_train = known_age['New_Age']\n",
    "    X_test = unknown_age[['Pclass', 'Title']]\n",
    "    \n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_ages = rfr.predict(X_test)\n",
    "    df.loc[df['New_Age'].isnull(), 'New_Age'] = predicted_ages\n",
    "    \n",
    "    return df\n",
    "\n",
    "impute_function = random_forest_impute\n",
    "df_data['New_Age'] = df_data['Age']\n",
    "df_data = impute_function(df_data)\n",
    "\n",
    "df_data['Age_Group'] = pd.cut(df_data['New_Age'], bins=[0, 14, 60, 100], labels=['0', '1', '2']) # ['Child', 'Adult', 'Senior']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find Best Hyper-parameter by Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, cross_val_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # 假设您已经加载并预处理了数据\n",
    "# # df_data = ...\n",
    "# # df_train = df_data[:len(df_train)]\n",
    "# # df_test = df_data[len(df_train):]\n",
    "\n",
    "# # 重新拆分数据\n",
    "# df_train = df_data[:len(df_train)]\n",
    "# df_test = df_data[len(df_train):]\n",
    "\n",
    "# # 训练集和标签\n",
    "# X_train = df_train.drop(labels=['Survived', 'PassengerId'], axis=1)\n",
    "# Y_train = df_train['Survived']\n",
    "# X_test = df_test.drop(labels=['Survived', 'PassengerId'], axis=1)\n",
    "# Y_test = df_test['Survived']\n",
    "\n",
    "# # 显示列名\n",
    "# print(X_train.columns)\n",
    "\n",
    "# # 特征选择\n",
    "# minor_features = ['Sex_Code', 'Pclass', 'FareBin_Code_5', 'Connected_Survival', 'Ti_Minor']\n",
    "\n",
    "# # 定义随机森林分类器\n",
    "# clf = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True)\n",
    "\n",
    "# # 使用GridSearchCV寻找最佳超参数\n",
    "# param_grid = {\n",
    "#     'clf__n_estimators': [100, 250, 500],\n",
    "#     'clf__min_samples_split': [2, 10, 20],\n",
    "#     'clf__max_depth': [None, 10, 20, 30]\n",
    "# }\n",
    "\n",
    "# # 创建pipeline\n",
    "# pipeline = Pipeline([('clf', clf)])\n",
    "\n",
    "# # 使用StratifiedShuffleSplit进行交叉验证\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=2)\n",
    "\n",
    "# # 执行GridSearchCV\n",
    "# grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3, scoring='accuracy', cv=cv)\n",
    "# grid_search.fit(X_train[minor_features], Y_train)\n",
    "\n",
    "# # 打印最佳得分和最佳估计器\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(grid_search.best_estimator_)\n",
    "\n",
    "# # 打印所有网格搜索的得分\n",
    "# # report(grid_search.cv_results_)  # 这里假设您有一个report函数来打印结果\n",
    "\n",
    "# print('-----grid search end------------')\n",
    "\n",
    "# X_Submit = df_test.drop(labels=['PassengerId'], axis=1)\n",
    "# best_model = grid_search.best_estimator_\n",
    "# predictions = best_model.predict(X_Submit[minor_features])\n",
    "\n",
    "# # 创建提交文件\n",
    "# submit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'], \"Survived\": predictions.astype(int)})\n",
    "# submit.to_csv(\"submit_best_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forrest with fare bin & median age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splits again beacuse we just engineered new feature\n",
    "# df_train = df_data[:len(df_train)]\n",
    "# df_test = df_data[len(df_train):]\n",
    "# # Training set and labels\n",
    "# X = df_train.drop(labels=['Survived','PassengerId'],axis=1)\n",
    "# Y = df_train['Survived']\n",
    "# # Show columns\n",
    "# X.columns\n",
    "\n",
    "# minor = ['Sex_Code','Pclass','FareBin_Code_5','Connected_Survival','Ti_Minor']\n",
    "# minor_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "# minor_Model.fit(X[minor], Y)\n",
    "# print('Minor oob score :%.5f' %(minor_Model.oob_score_),'   LB_Public : 0.82296')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forrest with fare clustering & age imputing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splits again beacuse we just engineered new feature\n",
    "# df_train = df_data[:len(df_train)]\n",
    "# df_test = df_data[len(df_train):]\n",
    "# # Training set and labels\n",
    "# X = df_train.drop(labels=['Survived','PassengerId'],axis=1)\n",
    "# Y = df_train['Survived']\n",
    "# # Show columns\n",
    "# X.columns\n",
    "\n",
    "# minor = ['Sex_Code','Pclass','FareDeck_Code_5','Connected_Survival','Age_Group']\n",
    "# minor_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "# minor_Model.fit(X[minor], Y)\n",
    "# print('Minor oob score :%.5f' %(minor_Model.oob_score_),'   LB_Public : 0.82296')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "# 再次分割数据集\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "\n",
    "# 训练集和标签\n",
    "X = df_train.drop(labels=['Survived', 'PassengerId'], axis=1)\n",
    "Y = df_train['Survived']\n",
    "\n",
    "# 特征选择\n",
    "minor = ['Sex_Code', 'Pclass', 'FareBin_Code_5', 'Connected_Survival', 'Ti_Minor']\n",
    "\n",
    "# 定义模型\n",
    "minor_Model = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True)\n",
    "\n",
    "# 绘制学习曲线\n",
    "train_sizes, train_scores, valid_scores = learning_curve(minor_Model, X[minor], Y, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# 计算训练和验证分数的均值和标准差\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "# 绘制学习曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score', color='r')\n",
    "plt.plot(train_sizes, valid_scores_mean, label='Cross-validation score', color='g')\n",
    "\n",
    "# 填充区域\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.1, color='g')\n",
    "\n",
    "# 图表信息\n",
    "plt.title('Learning Curve for RandomForestClassifier')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 输出OOB分数\n",
    "minor_Model.fit(X[minor], Y)\n",
    "print('Minor oob score : %.5f' % minor_Model.oob_score_, '   LB_Public : 0.82296')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n",
    "\n",
    "# minor_pred = minor_Model.predict(X_Submit[minor])\n",
    "\n",
    "# submit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n",
    "#                       \"Survived\":minor_pred.astype(int)})\n",
    "# submit.to_csv(\"submit_minor.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
