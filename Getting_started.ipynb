{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset And Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extra Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def title_mapping(title):\n",
    "    if title in ['Mr', 'Mrs', 'Miss', 'Master']:\n",
    "        return title\n",
    "    elif title in ['Don', 'Rev', 'Dr', 'Mme', 'Ms', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess', 'Jonkheer', 'Dona']:\n",
    "        return 'Rare'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def title_mapping_encode(title):\n",
    "    if title in ['Mr', 'Mrs', 'Miss', 'Master']:\n",
    "        return 1\n",
    "    elif title in ['Don', 'Rev', 'Dr', 'Mme', 'Ms', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess', 'Jonkheer', 'Dona']:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# introduce title feature\n",
    "train_data['Title'] = train_data['Name'].apply(get_title).apply(title_mapping)\n",
    "\n",
    "# introduce title feature with numerical encoding\n",
    "train_data['Title_encode'] = train_data['Name'].apply(get_title).apply(title_mapping_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deck(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return cabin[0]\n",
    "    \n",
    "def deck_mapping(deck):\n",
    "    deck_mapping_dict = {'Unknown': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 8}\n",
    "    return deck_mapping_dict.get(deck, 0)\n",
    "\n",
    "# introduce deck feature\n",
    "train_data['Deck'] = train_data['Cabin'].apply(get_deck)\n",
    "\n",
    "# introduce deck feature with numerical encoding\n",
    "train_data['Deck_encode'] = train_data['Deck'].apply(deck_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "train_data['IsAlone'] = train_data['FamilySize'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imputation of Missing Values in the Age Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips: uncomment the method you want to use before running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method 1: Linear Regression Imputation\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression_impute(df):\n",
    "    known_age = df[df['Age'].notnull()]\n",
    "    unknown_age = df[df['Age'].isnull()]\n",
    "    \n",
    "    X_train = known_age[['Pclass', 'SibSp', 'Parch', 'Fare', 'Title_encode']]\n",
    "    y_train = known_age['Age']\n",
    "    X_test = unknown_age[['Pclass', 'SibSp', 'Parch', 'Fare', 'Title_encode']]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_ages = lr.predict(X_test)\n",
    "    df.loc[df['Age'].isnull(), 'Age'] = predicted_ages\n",
    "    \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Method 2: Random Forest Imputation\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest_impute(df):\n",
    "    known_age = df[df['Age'].notnull()]\n",
    "    unknown_age = df[df['Age'].isnull()]\n",
    "    \n",
    "    X_train = known_age[['Pclass', 'SibSp', 'Parch', 'Fare', 'Title_encode']]\n",
    "    y_train = known_age['Age']\n",
    "    X_test = unknown_age[['Pclass', 'SibSp', 'Parch', 'Fare', 'Title_encode']]\n",
    "    \n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_ages = rfr.predict(X_test)\n",
    "    df.loc[df['Age'].isnull(), 'Age'] = predicted_ages\n",
    "    \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Method 3: K-Nearest Neighbors (KNN) Imputation\n",
    "\"\"\"\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def knn_impute(df):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df[['Age']] = imputer.fit_transform(df[['Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Title_encode']])[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute_function = linear_regression_impute\n",
    "impute_function = random_forest_impute\n",
    "# impute_function = knn_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before imputation:\")\n",
    "train_data[['Age']].describe() # for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = impute_function(train_data)\n",
    "print(\"After imputation:\")\n",
    "train_data[['Age']].describe() # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_dummies_train = pd.get_dummies(train_data['Deck'], prefix='Deck')\n",
    "dummies_Embarked = pd.get_dummies(train_data['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(train_data['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(train_data['Pclass'], prefix= 'Pclass')\n",
    "title_dummies_train = pd.get_dummies(train_data['Title'], prefix='Title')\n",
    "\n",
    "df = pd.concat([train_data, deck_dummies_train, dummies_Embarked, dummies_Sex, dummies_Pclass, title_dummies_train], axis=1)\n",
    "df.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title', 'Title_encode', 'Deck_encode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Reshape操作\n",
    "df['Age_scaled'] = scaler.fit_transform(df['Age'].values.reshape(-1, 1))\n",
    "df['Fare_scaled'] = scaler.fit_transform(df['Fare'].values.reshape(-1, 1))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe() # for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_fare(row):\n",
    "    if pd.isnull(row['Fare']):\n",
    "        return fare_means[row['Pclass']]\n",
    "    else:\n",
    "        return row['Fare']\n",
    "    \n",
    "# calculate the average fare for each class\n",
    "fare_means = test_data.groupby('Pclass')['Fare'].mean()\n",
    "    \n",
    "# introduce title feature\n",
    "test_data['Title'] = test_data['Name'].apply(get_title).apply(title_mapping)\n",
    "test_data['Title_encode'] = test_data['Name'].apply(get_title).apply(title_mapping_encode)\n",
    "\n",
    "test_data['Deck'] = test_data['Cabin'].apply(get_deck)\n",
    "test_data['Deck_encode'] = test_data['Deck'].apply(deck_mapping)\n",
    "\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "test_data['IsAlone'] = test_data['FamilySize'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# fill missing fare\n",
    "test_data['Fare'] = test_data.apply(fill_missing_fare, axis=1)\n",
    "\n",
    "# fill missing age\n",
    "test_data = impute_function(test_data)\n",
    "\n",
    "# one-hot encoding\n",
    "deck_dummies_test = pd.get_dummies(test_data['Deck'], prefix='Deck')\n",
    "dummies_Embarked = pd.get_dummies(test_data['Embarked'], prefix='Embarked')\n",
    "dummies_Sex = pd.get_dummies(test_data['Sex'], prefix='Sex')\n",
    "dummies_Pclass = pd.get_dummies(test_data['Pclass'], prefix='Pclass')\n",
    "title_dummies_test = pd.get_dummies(test_data['Title'], prefix='Title')\n",
    "\n",
    "df_test = pd.concat([test_data, deck_dummies_test, dummies_Embarked, dummies_Sex, dummies_Pclass, title_dummies_test], axis=1)\n",
    "\n",
    "df_test.drop(['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title', 'Title_encode', 'Deck_encode'], axis=1, inplace=True)\n",
    "\n",
    "# fix missing one-hot encodes\n",
    "df_test['Title_Unknown'] = 0\n",
    "df_test['Deck_T'] = 0\n",
    "\n",
    "# standardize\n",
    "df_test['Age_scaled'] = scaler.fit_transform(df_test['Age'].values.reshape(-1, 1))\n",
    "df_test['Fare_scaled'] = scaler.fit_transform(df_test['Fare'].values.reshape(-1, 1))\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a naive version, we use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|FamilySize|IsAlone|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*|Title_.*')\n",
    "train_np = train_df.values\n",
    "\n",
    "y = train_np[:, 0]\n",
    "\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n",
    "clf.fit(X, y.astype(\"int\"))\n",
    "    \n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use trained model to predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.filter(regex='Age_.*|SibSp|Parch|FamilySize|IsAlone|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*|Title_.*')\n",
    "predictions = clf.predict(test)\n",
    "result = pd.DataFrame({'PassengerId':test_data['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n",
    "result.to_csv(\"logistic_regression_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
