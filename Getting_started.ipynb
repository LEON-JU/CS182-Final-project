{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset And Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# loading data\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_data = pd.concat([df_train, df_test], ignore_index=True)  # Concatenate train and test datasets\n",
    "# for display dataframe\n",
    "from IPython.display import display\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex\n",
    "df_data['Sex_Code'] = df_data['Sex'].map({'female' : 1, 'male' : 0}).astype('int')\n",
    "# split training set the testing set\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "# Inputs set and labels\n",
    "X = df_train.drop(labels=['Survived','PassengerId'],axis=1)\n",
    "Y = df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base oob score :0.73176    LB_Public : 0.76555\n"
     ]
    }
   ],
   "source": [
    "# Show Baseline\n",
    "Base = ['Sex_Code','Pclass']\n",
    "Base_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "Base_Model.fit(X[Base], Y)\n",
    "print('Base oob score :%.5f' %(Base_Model.oob_score_),'   LB_Public : 0.76555')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some bugs in log-scale of boxplot. \n",
    "# alternatively, we transform x into log10(x) for visualization.\n",
    "df_data['Log_Fare'] = (df_data['Fare']+1).map(lambda x : np.log10(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "df_data['Fare'] = df_data['Fare'].fillna(df_data['Fare'].median())\n",
    "\n",
    "# Making Bins\n",
    "df_data['FareBin_4'] = pd.qcut(df_data['Fare'], 4)\n",
    "df_data['FareBin_5'] = pd.qcut(df_data['Fare'], 5)\n",
    "df_data['FareBin_6'] = pd.qcut(df_data['Fare'], 6)\n",
    "\n",
    "label = LabelEncoder()\n",
    "df_data['FareBin_Code_4'] = label.fit_transform(df_data['FareBin_4'])\n",
    "df_data['FareBin_Code_5'] = label.fit_transform(df_data['FareBin_5'])\n",
    "df_data['FareBin_Code_6'] = label.fit_transform(df_data['FareBin_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family_size\n",
    "df_data['Family_size'] = df_data['SibSp'] + df_data['Parch'] + 1\n",
    "# how about the fare values of deplicate tickets \n",
    "deplicate_ticket = []\n",
    "for tk in df_data.Ticket.unique():\n",
    "    tem = df_data.loc[df_data.Ticket == tk, 'Fare']\n",
    "    #print(tem.count())\n",
    "    if tem.count() > 1:\n",
    "        #print(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare']])\n",
    "        deplicate_ticket.append(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare','Cabin','Family_size','Survived']])\n",
    "deplicate_ticket = pd.concat(deplicate_ticket)\n",
    "# deplicate_ticket.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Connected_Survival'] = 0.5 # default \n",
    "for _, df_grp in df_data.groupby('Ticket'):\n",
    "    if (len(df_grp) > 1):\n",
    "        for ind, row in df_grp.iterrows():\n",
    "            smax = df_grp.drop(ind)['Survived'].max()\n",
    "            smin = df_grp.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # of masters we found in missing Age by Title :  8\n"
     ]
    }
   ],
   "source": [
    "# extracted title using name\n",
    "df_data['Title'] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df_data['Title'] = df_data['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n",
    "                                               'Dr', 'Dona', 'Jonkheer', \n",
    "                                                'Major','Rev','Sir'],'Rare') \n",
    "df_data['Title'] = df_data['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\n",
    "df_data['Title'] = df_data['Title'].replace(['Lady'],'Mrs')\n",
    "df_data['Title'] = df_data['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })\n",
    "Ti_pred = df_data.groupby('Title')['Age'].median().values\n",
    "df_data['Ti_Age'] = df_data['Age']\n",
    "# Filling the missing age\n",
    "for i in range(0,5):\n",
    " # 0 1 2 3 4 5\n",
    "    df_data.loc[(df_data.Age.isnull()) & (df_data.Title == i),'Ti_Age'] = Ti_pred[i]\n",
    "df_data['Ti_Age'] = df_data['Ti_Age'].astype('int')\n",
    "\n",
    "# extract minor\n",
    "df_data['Age_copy'] = df_data['Age'].fillna(-1)\n",
    "df_data['Minor'] = (df_data['Age_copy'] < 14.0) & (df_data['Age_copy']>= 0)\n",
    "df_data['Minor'] = df_data['Minor'] * 1\n",
    "# We could capture more 8 Master in Pclass = 3 by filling missing age \n",
    "df_data['Ti_Minor'] = ((df_data['Ti_Age']) < 14.0) * 1\n",
    "print('The # of masters we found in missing Age by Title : ', (df_data['Ti_Minor'] - df_data['Minor']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minor oob score :0.84400    LB_Public : 0.82296\n"
     ]
    }
   ],
   "source": [
    "# splits again beacuse we just engineered new feature\n",
    "df_train = df_data[:len(df_train)]\n",
    "df_test = df_data[len(df_train):]\n",
    "# Training set and labels\n",
    "X = df_train.drop(labels=['Survived','PassengerId'],axis=1)\n",
    "Y = df_train['Survived']\n",
    "# Show columns\n",
    "X.columns\n",
    "\n",
    "minor = ['Sex_Code','Pclass','FareBin_Code_5','Connected_Survival','Ti_Minor']\n",
    "minor_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "minor_Model.fit(X[minor], Y)\n",
    "print('Minor oob score :%.5f' %(minor_Model.oob_score_),'   LB_Public : 0.82296')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n",
    "\n",
    "# minor_pred = minor_Model.predict(X_Submit[minor])\n",
    "\n",
    "# submit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n",
    "#                       \"Survived\":minor_pred.astype(int)})\n",
    "# submit.to_csv(\"submit_minor.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
